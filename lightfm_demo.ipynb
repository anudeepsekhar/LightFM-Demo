{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightFM Demo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Movielense data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n",
    "req = requests.get(url, stream=True)\n",
    "\n",
    "dest_path = 'data/movielense.zip'\n",
    "\n",
    "if not os.path.exists(dest_path):\n",
    "    with open(dest_path, \"wb\") as fd:\n",
    "        for chunk in req.iter_content():\n",
    "            fd.write(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_data(dest_path):\n",
    "    with zipfile.ZipFile(dest_path) as datafile:\n",
    "        train_raw = datafile.read(\"ml-100k/ua.base\").decode().split(\"\\n\")\n",
    "        test_raw = datafile.read(\"ml-100k/ua.test\").decode().split(\"\\n\")\n",
    "    return train_raw, test_raw\n",
    "train_raw, test_raw = get_raw_data(dest_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data contains user_id, item_id, rating and timestamp which are tab seperated and have to be parsed. To do so we create a generator that will parse the data for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(data):\n",
    "    for line in data:\n",
    "\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        uid, iid, rating, timestamp = [int(x) for x in line.split(\"\\t\")]\n",
    "\n",
    "        yield uid, iid, rating, timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets explore the data a bit..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for uid, iid, rating, timestamp in parse(train_raw):\n",
    "    data.append([uid, iid, rating, timestamp])\n",
    "for uid, iid, rating, timestamp in parse(test_raw):\n",
    "    data.append([uid, iid, rating, timestamp])\n",
    "df = pd.DataFrame(data, columns=['user_id', 'item_id', 'rating', 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>874965758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>876893171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>878542960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>876893119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>889751712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0        1        1       5  874965758\n",
       "1        1        2       3  876893171\n",
       "2        1        3       4  878542960\n",
       "3        1        4       3  876893119\n",
       "4        1        5       3  889751712"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ratings: 100000\n",
      "Number of users: 943\n",
      "Number of movies: 1682\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of ratings: {len(df)}')\n",
    "print(f'Number of users: {len(df[\"user_id\"].unique())}')\n",
    "print(f'Number of movies: {len(df[\"item_id\"].unique())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the user-item interaction matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightFM expects a (no_users, no_items) sparse matrix (with 1s denoting positive, and -1s negative interactions), so lets build that...\n",
    "\n",
    "We will consider movie ratings > 4.0 as positive ratings and others as negative ratings and create an interaction matrix and store it as a sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_interaction_matrix(rows, cols, data):\n",
    "    \"\"\"\n",
    "    Build the training matrix (no_users, no_items),\n",
    "    with ratings >= 4.0 being marked as positive and\n",
    "    the rest as negative.\n",
    "    \"\"\"\n",
    "\n",
    "    mat = sp.lil_matrix((rows, cols), dtype=np.int32)\n",
    "\n",
    "    for uid, iid, rating, timestamp in data:\n",
    "        if rating >= 4.0:\n",
    "            mat[uid, iid] = 1.0\n",
    "        else:\n",
    "            mat[uid, iid] = -1.0\n",
    "\n",
    "    return mat.tocoo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "944 1683\n"
     ]
    }
   ],
   "source": [
    "rows = len(df[\"user_id\"].unique()) + 1\n",
    "cols = len(df[\"item_id\"].unique()) + 1\n",
    "\n",
    "print(rows, cols)\n",
    "\n",
    "train = build_interaction_matrix(rows, cols, parse(train_raw))\n",
    "test = build_interaction_matrix(rows, cols, parse(test_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(944, 1683)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Raw Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information about the items (movies) is a tab separated list of movie id | movie title | release date | video release date | IMDb URL | unknown | Action | Adventure | Animation | Children's | Comedy | Crime | Documentary | Drama | Fantasy | Film-Noir | Horror | Musical | Mystery | Romance | Sci-Fi | Thriller | War | Western | The last 19 fields are the genres, a 1 indicates the movie is of that genre, a 0 indicates it is not; movies can be in several genres at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_movie_meta(dest_path):\n",
    "    with zipfile.ZipFile(dest_path) as datafile:\n",
    "        movie_meta = datafile.read(\"ml-100k/u.item\").decode(errors=\"ignore\").split(\"\\n\")\n",
    "    return movie_meta\n",
    "movie_meta_raw = get_raw_movie_meta(dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1|Toy Story (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Toy%20Story%20(1995)|0|0|0|1|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0',\n",
       " '2|GoldenEye (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?GoldenEye%20(1995)|0|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0|1|0|0',\n",
       " '3|Four Rooms (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Four%20Rooms%20(1995)|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|1|0|0',\n",
       " '4|Get Shorty (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Get%20Shorty%20(1995)|0|1|0|0|0|1|0|0|1|0|0|0|0|0|0|0|0|0|0',\n",
       " '5|Copycat (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Copycat%20(1995)|0|0|0|0|0|0|1|0|1|0|0|0|0|0|0|0|1|0|0']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_meta_raw[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_labels(item_meta_raw):\n",
    "    labels = ['']\n",
    "    for line in item_meta_raw:\n",
    "\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        splt = line.split(\"|\")\n",
    "        item_label = splt[1]\n",
    "        labels.append(item_label)\n",
    "    return np.array(labels)\n",
    "\n",
    "item_labels = get_item_labels(movie_meta_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Item Features\n",
    "To use the item meta data as feature in LightFM we need to convert the raw data into a (no_items, no_features) sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movielens_item_metadata(raw_data, use_item_ids):\n",
    "    \"\"\"\n",
    "    Build a matrix of genre features (no_items, no_features).\n",
    "    If use_item_ids is True, per-item features will also be used.\n",
    "    \"\"\"\n",
    "\n",
    "    features = {}\n",
    "    genre_set = set()\n",
    "\n",
    "    for line in raw_data:\n",
    "\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        splt = line.split(\"|\")\n",
    "        item_id = int(splt[0])\n",
    "\n",
    "        genres = [\n",
    "            idx for idx, val in zip(range(len(splt[5:])), splt[5:]) if int(val) > 0\n",
    "        ]\n",
    "\n",
    "        if use_item_ids:\n",
    "            # Add item-specific features too\n",
    "            genres.append(item_id)\n",
    "\n",
    "        for genre_id in genres:\n",
    "            genre_set.add(genre_id)\n",
    "\n",
    "        features[item_id] = genres\n",
    "\n",
    "    mat = sp.lil_matrix((len(features) + 1, len(genre_set)), dtype=np.int32)\n",
    "\n",
    "    for item_id, genre_ids in features.items():\n",
    "        for genre_id in genre_ids:\n",
    "            mat[item_id, genre_id] = 1\n",
    "\n",
    "    return mat\n",
    "item_features = get_movielens_item_metadata(movie_meta_raw, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Raw User Data \n",
    "The user data is tab seperated list of Demographic information about the users; this is a tab separated list of user id | age | gender | occupation | zip code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_user_meta(dest_path):\n",
    "    with zipfile.ZipFile(dest_path) as datafile:\n",
    "        user_meta = datafile.read(\"ml-100k/u.user\").decode(errors=\"ignore\").split(\"\\n\")\n",
    "    return user_meta\n",
    "user_meta_raw = get_raw_user_meta(dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1|24|M|technician|85711',\n",
       " '2|53|F|other|94043',\n",
       " '3|23|M|writer|32067',\n",
       " '4|24|M|technician|43537',\n",
       " '5|33|F|other|15213']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_meta_raw[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building The Model\n",
    "Now that we have processed our data we are ready to build our model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anudeepsekhar/Projects/yes/envs/seai/lib/python3.9/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k, auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "LightFM implements two algorithms that have proven particular successful:\n",
    "\n",
    "BPR: Bayesian Personalised Ranking pairwise loss. Maximises the prediction difference between a positive example and a randomly chosen negative example. Useful when only positive interactions are present and optimising ROC AUC is desired.\n",
    "\n",
    "WARP: Weighted Approximate-Rank Pairwise loss. Maximises the rank of positive examples by repeatedly sampling negative examples until rank violating one is found. Useful when only positive interactions are present and optimising the top of the recommendation list (precision@k) is desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x157eba8b0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LightFM(no_components=30)\n",
    "model.fit(train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.6307819485664368\n",
      "Precision: 0.033881232142448425\n"
     ]
    }
   ],
   "source": [
    "test_precision = precision_at_k(model, test, k=20).mean()\n",
    "test_auc = auc_score(model, test).mean()\n",
    "print(f'AUC: {test_auc}')\n",
    "print(f'Precision: {test_precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x14796aa60>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LightFM(loss='warp')\n",
    "model.fit(train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8916676044464111\n",
      "Precision: 0.09490986168384552\n"
     ]
    }
   ],
   "source": [
    "test_precision = precision_at_k(model, test, k=20).mean()\n",
    "test_auc = auc_score(model, test).mean()\n",
    "print(f'AUC: {test_auc}')\n",
    "print(f'Precision: {test_precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1683, 1683)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x157f19e50>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LightFM(loss='warp', no_components=30)\n",
    "model.fit(train,\n",
    "          item_features=item_features,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8883857727050781\n",
      "Precision: 0.08594910055398941\n"
     ]
    }
   ],
   "source": [
    "test_precision = precision_at_k(model, test, k=20, item_features=item_features).mean()\n",
    "test_auc = auc_score(model, test, item_features=item_features).mean()\n",
    "print(f'AUC: {test_auc}')\n",
    "print(f'Precision: {test_precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_recommendation(model, train_data, user_ids, item_labels, topk=5):\n",
    "    n_users, n_items = train_data.shape\n",
    "    for user_id in user_ids: \n",
    "        #movies they always like\n",
    "        known_positives = item_labels[train.tocsr()[user_id].indices]\n",
    "        scores = model.predict(user_id, np.arange(n_items))\n",
    "        #rank in order of most liked to least\n",
    "        top_items = item_labels[np.argsort(-scores)]\n",
    "        #print results\n",
    "        print(\"\\nUser %s\" % user_id)\n",
    "        print(\"Most Liked:\")\n",
    "\n",
    "        for x in known_positives[:topk]:\n",
    "            print(\"%s\" % x)\n",
    "        \n",
    "        print(\"Recommend:\")\n",
    "\n",
    "        for x in top_items[:topk]:\n",
    "            print(\"%s\" % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User 1\n",
      "Most Liked:\n",
      "Toy Story (1995)\n",
      "GoldenEye (1995)\n",
      "Four Rooms (1995)\n",
      "Get Shorty (1995)\n",
      "Copycat (1995)\n",
      "Recommend:\n",
      "Star Wars (1977)\n",
      "Raiders of the Lost Ark (1981)\n",
      "Godfather, The (1972)\n",
      "Lawrence of Arabia (1962)\n",
      "Chasing Amy (1997)\n"
     ]
    }
   ],
   "source": [
    "sample_recommendation(model, train, [1], item_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('seai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2ec49568dd6695f65fa276b8a52455821de066ca3cd4dcf0d05a4f179d3befe9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
